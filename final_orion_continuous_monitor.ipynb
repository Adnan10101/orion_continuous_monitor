{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdtnFWX-PKCw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDDgsDKp2FAE"
      },
      "source": [
        "## init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA9bQMozM_wg",
        "outputId": "0f593833-f2fc-4e67-c36c-2e274056e1a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Nov 23 19:04:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKPgeWuPomxc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx8UNmABNkJP",
        "outputId": "a6bfd183-1b3c-44df-eee0-9789b9dc5e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOME: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YdVKyDJooFR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CBrYxp6nNpqk",
        "outputId": "ffa1fe15-4e1b-41c4-8a44-6461db20539a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'segment-anything-2'...\n",
            "remote: Enumerating objects: 1070, done.\u001b[K\n",
            "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1070/1070), 128.11 MiB | 19.07 MiB/s, done.\n",
            "Resolving deltas: 100% (381/381), done.\n",
            "/content/segment-anything-2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.41.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-8.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting botocore<1.42.0,>=1.41.2 (from boto3)\n",
            "  Downloading botocore-1.41.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.16.0,>=0.15.0 (from boto3)\n",
            "  Downloading s3transfer-0.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.11.12)\n",
            "Requirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.4)\n",
            "Collecting pinecone-plugin-assistant<4.0.0,>=3.0.1 (from pinecone)\n",
            "  Downloading pinecone_plugin_assistant-3.0.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pinecone-plugin-interface<0.1.0,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Collecting packaging>=20.9 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading boto3-1.41.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-8.0.0-py3-none-any.whl (745 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m745.9/745.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.41.2-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading pinecone_plugin_assistant-3.0.1-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.9/280.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading s3transfer-0.15.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-interface, packaging, jmespath, pinecone-plugin-assistant, botocore, s3transfer, pinecone, boto3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "Successfully installed boto3-1.41.2 botocore-1.41.2 jmespath-1.0.1 packaging-24.2 pinecone-8.0.0 pinecone-plugin-assistant-3.0.1 pinecone-plugin-interface-0.0.7 s3transfer-0.15.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "33dfd979ebb04c4883f3886b61d0c50a",
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/segment-anything-2.git\n",
        "%cd {HOME}/segment-anything-2\n",
        "!pip install -e . -q\n",
        "!pip install -q supervision jupyter_bbox_widget\n",
        "!mkdir -p {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt -P {HOME}/checkpoints\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt -P {HOME}/checkpoints\n",
        "!pip install boto3 sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxF9GF4YPQel"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZY_hX8kP_Hg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaWWxUyeI4N4"
      },
      "source": [
        "## init 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba0Wr9TQrtjg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH_UQxmKrtvE",
        "outputId": "1ae5b5ec-b673-4887-c020-f282b6131dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ngrok\n",
            "  Downloading ngrok-1.6.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Downloading ngrok-1.6.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvaz_qCkrtvF",
        "outputId": "2e517737-6630-4aa4-e527-383017ac4cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9q-NEumoyPT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import base64\n",
        "\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ztwdI5rYGM",
        "outputId": "65a904cf-37e6-470b-f730-e8204bbd4a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2wgvr7Owm7e",
        "outputId": "9d7084f8-4dde-44c8-be44-a27168107a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (0.28.0)\n",
            "Collecting openai\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.0\n",
            "    Uninstalling openai-0.28.0:\n",
            "      Successfully uninstalled openai-0.28.0\n",
            "Successfully installed openai-2.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGFardR1LhtI"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p {HOME}/checkpoints\n",
        "# !wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P {HOME}/checkpoints\n",
        "# !wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt -P {HOME}/checkpoints\n",
        "# !wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt -P {HOME}/checkpoints\n",
        "# !wget -q https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt -P {HOME}/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHUR2ZmXHPMK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pUslL7kD5QF"
      },
      "source": [
        "## Main code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVws4KK7D5QF"
      },
      "outputs": [],
      "source": [
        "# main\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "import io\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "import supervision as sv\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import uuid\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "from openai import OpenAI  # Changed from import openai\n",
        "import logging\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oye1o3TCD5QF"
      },
      "outputs": [],
      "source": [
        "# main\n",
        "import boto3\n",
        "class S3ImageStorageManager:\n",
        "    \"\"\"Manages image storage in AWS S3\"\"\"\n",
        "\n",
        "    def __init__(self, bucket_name: str, aws_access_key_id: str,\n",
        "                 aws_secret_access_key: str, region_name: str = 'us-east-1'):\n",
        "        \"\"\"Initialize S3 client\"\"\"\n",
        "        self.s3_client = boto3.client(\n",
        "            's3',\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            region_name=region_name\n",
        "        )\n",
        "        self.bucket_name = bucket_name\n",
        "        self.region_name = region_name\n",
        "\n",
        "    def upload_base64_image(self, base64_image: str, prefix: str = 'frames/') -> str:\n",
        "        \"\"\"\n",
        "        Upload base64 encoded image to S3 and return public URL\n",
        "\n",
        "        Returns:\n",
        "        - Public S3 URL to access the image\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Decode base64 image\n",
        "            image_bytes = base64.b64decode(base64_image)\n",
        "\n",
        "            # Generate unique filename with timestamp\n",
        "            timestamp = int(time.time())\n",
        "            filename = f\"{prefix}{timestamp}_{uuid.uuid4()}.png\"\n",
        "\n",
        "            # Upload to S3 with public-read ACL\n",
        "            self.s3_client.put_object(\n",
        "                Bucket=self.bucket_name,\n",
        "                Key=filename,\n",
        "                Body=image_bytes,\n",
        "                ContentType='image/png',\n",
        "\n",
        "            )\n",
        "\n",
        "            # Generate public URL\n",
        "            public_url = f\"https://{self.bucket_name}.s3.{self.region_name}.amazonaws.com/{filename}\"\n",
        "\n",
        "            print(f\"âœ… Uploaded to S3: {filename}\")\n",
        "            return public_url\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error uploading image to S3: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_MHjcu-D5QG"
      },
      "outputs": [],
      "source": [
        "#main\n",
        "import requests\n",
        "\n",
        "def store_in_image_analysis_db(\n",
        "    patient_id: str,\n",
        "    session_id: str,\n",
        "    original_image_url: str,\n",
        "    segmented_image_url: str,\n",
        "    description: str,\n",
        "    timestamp: float\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Store image analysis in database via API\n",
        "\n",
        "    Returns:\n",
        "    - API response with analysis_id\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = {\n",
        "            \"patient_id\": patient_id,\n",
        "            \"session_id\": session_id,\n",
        "            \"image_type\": \"surgical_frame\",  # You can make this dynamic\n",
        "            \"original_image_url\": original_image_url,\n",
        "            \"segmented_image_url\": segmented_image_url,\n",
        "            \"description\": description,\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            IMAGE_ANALYSIS_API,\n",
        "            json=payload,\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            analysis_id = result.get('result', {}).get('analysis_id', 'Unknown')\n",
        "            print(f\"âœ… Stored in DB with analysis_id: {analysis_id}\")\n",
        "            return result\n",
        "        else:\n",
        "            print(f\"âš ï¸ Failed to store in DB: {response.status_code}\")\n",
        "            print(f\"   Response: {response.text}\")\n",
        "            raise Exception(f\"Database storage failed: {response.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error storing in database: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2W2fzRTD5QG"
      },
      "outputs": [],
      "source": [
        "# main\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import sys\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Apply nest_asyncio patch to allow nested event loops in Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def start_server_threaded(app, port, ngrok_token):\n",
        "    \"\"\"\n",
        "    Start the server in a separate thread with Ngrok tunnel\n",
        "\n",
        "    Args:\n",
        "    - app: FastAPI application instance\n",
        "    - port: Port to run the server on\n",
        "    - ngrok_token: Ngrok authentication token\n",
        "    \"\"\"\n",
        "    # Set Ngrok auth token\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "    try:\n",
        "        # Create ngrok tunnel\n",
        "        public_url = ngrok.connect(port, proto=\"http\")\n",
        "\n",
        "        # Print connection details\n",
        "        print(f\"ğŸŒ Public URL: {public_url}\")\n",
        "        print(f\"\\nâœ… Server is ready!\")\n",
        "        print(f\"\\nUse this URL in Unity:\")\n",
        "        print(f\"   {public_url}/segment\")\n",
        "        print(f\"\\nTest health check:\")\n",
        "        print(f\"   {public_url}/health\")\n",
        "\n",
        "        # Prepare uvicorn configuration\n",
        "        config = uvicorn.Config(app, host=\"0.0.0.0\", port=port)\n",
        "        server = uvicorn.Server(config)\n",
        "\n",
        "        # Run the server\n",
        "        asyncio.run(server.serve())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error starting server: {e}\")\n",
        "    finally:\n",
        "        # Disconnect all ngrok tunnels\n",
        "        ngrok.kill()\n",
        "\n",
        "def setup_and_run_server(app, ngrok_token, port=5556):\n",
        "    \"\"\"\n",
        "    Comprehensive setup and server startup function for Colab\n",
        "\n",
        "    Args:\n",
        "    - app: FastAPI application instance\n",
        "    - ngrok_token: Your Ngrok authentication token\n",
        "    - port: Port to run the server on (default 5556)\n",
        "    \"\"\"\n",
        "    # Install dependencies\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
        "                           'fastapi', 'uvicorn', 'pyngrok',\n",
        "                           'nest_asyncio', 'torch', 'transformers',\n",
        "                           'opencv-python-headless', 'supervision'])\n",
        "\n",
        "    # Apply nest_asyncio patch\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "\n",
        "    server_thread = threading.Thread(\n",
        "        target=start_server_threaded,\n",
        "        args=(app, port, ngrok_token),\n",
        "        daemon=True\n",
        "    )\n",
        "    server_thread.start()\n",
        "\n",
        "\n",
        "    return server_thread\n",
        "\n",
        "IMAGE_ANALYSIS_API = \"https://jp758vdtak.us-east-1.awsapprunner.com/table/image_analysis\"\n",
        "\n",
        "# Simplified store_frame function - RDS only\n",
        "def store_frame_data(\n",
        "    patient_id: str,\n",
        "    session_id: str,\n",
        "    frame_base64: str,\n",
        "    segmented_frame: str,\n",
        "    caption: str\n",
        "):\n",
        "    \"\"\"\n",
        "    Store frame data in AWS RDS only:\n",
        "    - Images uploaded to S3\n",
        "    - All metadata and caption stored in RDS\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Upload images to S3\n",
        "        original_frame_url = s3_manager.upload_base64_image(frame_base64, prefix='original/')\n",
        "        segmented_frame_url = s3_manager.upload_base64_image(segmented_frame, prefix='segmented/')\n",
        "\n",
        "        timestamp = time.time()\n",
        "\n",
        "        # Store everything in AWS RDS\n",
        "        db_result = store_in_image_analysis_db(\n",
        "            patient_id=patient_id,\n",
        "            session_id=session_id,\n",
        "            original_image_url=original_frame_url,\n",
        "            segmented_image_url=segmented_frame_url,\n",
        "            description=caption,\n",
        "            timestamp=timestamp\n",
        "        )\n",
        "\n",
        "        analysis_id = db_result.get('result', {}).get('analysis_id')\n",
        "        print(f\"âœ… Stored in RDS with analysis_id: {analysis_id}\")\n",
        "\n",
        "        return {\n",
        "            \"analysis_id\": analysis_id,\n",
        "            \"original_url\": original_frame_url,\n",
        "            \"segmented_url\": segmented_frame_url\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Storage error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMHwNHnbD5QG"
      },
      "outputs": [],
      "source": [
        "# main\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "import io\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "import supervision as sv\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import uuid\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "from openai import OpenAI  # Changed from import openai\n",
        "import logging\n",
        "import re\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Initialize models and embeddings\n",
        "\n",
        "##################### UPDATE THESE PATHS!!!!!!! #####################################\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "CHECKPOINT = \"/content/checkpoints/sam2_hiera_large.pt\"\n",
        "CONFIG = \"sam2_hiera_l.yaml\"\n",
        "\n",
        "\n",
        "\n",
        "sam2_model = build_sam2(CONFIG, CHECKPOINT, device=DEVICE, apply_postprocessing=False)\n",
        "sam2_model.eval()\n",
        "\n",
        "mask_generator = SAM2AutomaticMaskGenerator(\n",
        "    model=sam2_model,\n",
        "    points_per_side=16,\n",
        "    points_per_batch=128,\n",
        "    pred_iou_thresh=0.6,\n",
        "    stability_score_thresh=0.9,\n",
        "    stability_score_offset=0.7,\n",
        "    crop_n_layers=0,\n",
        "    box_nms_thresh=0.7,\n",
        "    min_mask_region_area=0,\n",
        "    apply_postprocessing=False\n",
        ")\n",
        "\n",
        "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "\n",
        "\n",
        "# Shared Processing Pool\n",
        "executor = ThreadPoolExecutor(max_workers=2)\n",
        "\n",
        "# OpenAI client (global variable)\n",
        "client = None\n",
        "\n",
        "# Request model\n",
        "class FrameRequest(BaseModel):\n",
        "    frame_base64: str\n",
        "    patient_id: str = \"None\" \n",
        "    session_id: str = None  \n",
        "    frame_id: str = None  \n",
        "\n",
        "\n",
        "\n",
        "def initialize_openai(api_key: str):\n",
        "    \"\"\"Initialize OpenAI client\"\"\"\n",
        "    global client\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "def process_segment(frame_base64: str) -> dict:\n",
        "    \"\"\"Process segmentation for a frame\"\"\"\n",
        "    try:\n",
        "        # Decode the base64 image to a numpy array\n",
        "        image_bytes = base64.b64decode(frame_base64)\n",
        "        npimg = np.frombuffer(image_bytes, np.uint8)\n",
        "        image_bgr = cv2.imdecode(npimg, cv2.IMREAD_COLOR)\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Generate segmentation mask\n",
        "        sam2_result = mask_generator.generate(image_rgb)\n",
        "        detections = sv.Detections.from_sam(sam_result=sam2_result)\n",
        "\n",
        "        # Annotate the frame\n",
        "        annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "        # Encode back to base64\n",
        "        _, buffer = cv2.imencode(\".png\", annotated_image)\n",
        "        encoded_image = base64.b64encode(buffer).decode(\"utf-8\")\n",
        "\n",
        "        return {\"segmented_frame\": encoded_image}\n",
        "    except Exception as e:\n",
        "        print(f\"Segmentation error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "def clean_caption(original_caption: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and extract the core description from the caption\n",
        "    \"\"\"\n",
        "    # Remove common reasoning prefixes and introductory phrases\n",
        "    prefixes_to_remove = [\n",
        "        \"i need to create a concise technical description\",\n",
        "        \"i can't mention reasoning steps\",\n",
        "        \"i should stick to describing\",\n",
        "        \"the user wants\",\n",
        "        \"i will focus on\",\n",
        "        \"describing surgical scene\"\n",
        "    ]\n",
        "\n",
        "    # Convert to lowercase for matching\n",
        "    lower_caption = original_caption.lower()\n",
        "\n",
        "    # Find the actual descriptive content\n",
        "    for prefix in prefixes_to_remove:\n",
        "        if prefix in lower_caption:\n",
        "            # Split the caption and take the most substantive part\n",
        "            parts = original_caption.split(prefix)\n",
        "            if len(parts) > 1:\n",
        "                caption = parts[-1].strip()\n",
        "                break\n",
        "    else:\n",
        "        caption = original_caption\n",
        "\n",
        "    # Remove any remaining reasoning language\n",
        "    caption = re.sub(r'^(i|the model|it seems|from the image).+?:\\s*', '', caption, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove quotation marks and excessive whitespace\n",
        "    caption = caption.strip('\"').strip()\n",
        "\n",
        "    return caption\n",
        "\n",
        "\n",
        "def process_caption(frame_base64: str) -> str:\n",
        "    \"\"\"Generate clean, reasoning-free caption for a frame using OpenAI Vision API.\"\"\"\n",
        "    global client\n",
        "    if client is None:\n",
        "        raise HTTPException(status_code=500, detail=\"OpenAI client not initialized\")\n",
        "\n",
        "    try:\n",
        "        # --- Step 1: Validate base64 image ---\n",
        "        try:\n",
        "            image_data = base64.b64decode(frame_base64)\n",
        "            logging.info(f\"Image decode successful. Length: {len(image_data)} bytes\")\n",
        "        except Exception as decode_error:\n",
        "            logging.error(f\"Base64 decoding error: {decode_error}\")\n",
        "            return \"Invalid image data\"\n",
        "\n",
        "        # --- Step 2: Call OpenAI Vision API ---\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o\",  # Use gpt-4o for vision capabilities\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": (\n",
        "                                    # could work on this probably\n",
        "                                    \"Provide ONLY a concise, factual description of the contents of this surgical scene. \"\n",
        "                                    \"Focus strictly on visible instruments, drapes, tubing, and equipment layout. \"\n",
        "                                    \"DO NOT include any reasoning, self-comments, thoughts, or analysis steps. \"\n",
        "                                    \"Output should be a final descriptive sentence or paragraph suitable for a caption, \"\n",
        "                                    \"maximum 500 words. \"\n",
        "                                    \"Avoid any markdown, headings, or formatting. Start directly with the description.\"\n",
        "                                ),\n",
        "                            },\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": f\"data:image/jpeg;base64,{frame_base64}\"\n",
        "                                },\n",
        "                            },\n",
        "                        ],\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "            )\n",
        "\n",
        "            logging.info(f\"OpenAI Response received successfully\")\n",
        "\n",
        "        except Exception as api_error:\n",
        "            logging.error(f\"OpenAI API Error: {api_error}\")\n",
        "            return f\"API error: {str(api_error)}\"\n",
        "\n",
        "\n",
        "        caption = \"\"\n",
        "        try:\n",
        "            if response.choices and len(response.choices) > 0:\n",
        "                caption = response.choices[0].message.content.strip()\n",
        "            else:\n",
        "                logging.warning(\"No choices returned from OpenAI\")\n",
        "                return \"No response generated\"\n",
        "\n",
        "        except Exception as extract_error:\n",
        "            logging.error(f\"Caption extraction error: {extract_error}\")\n",
        "            return \"Failed to extract caption\"\n",
        "\n",
        "\n",
        "        caption = clean_caption(caption)\n",
        "\n",
        "        logging.info(f\"Final Clean Caption: {caption}\")\n",
        "\n",
        "        return caption if caption else \"No meaningful caption generated\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error in caption generation: {e}\")\n",
        "        return f\"Unexpected error: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/process_frames\")\n",
        "async def process_frame(req: FrameRequest):\n",
        "    \"\"\"\n",
        "    Unified endpoint for parallel processing of frame segmentation and captioning\n",
        "    Stores everything in AWS RDS (no Pinecone)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Generate session_id if not provided\n",
        "        if not req.session_id:\n",
        "            req.session_id = f\"session-{req.patient_id}-{int(time.time())}\"\n",
        "\n",
        "        # Run segmentation and captioning in parallel\n",
        "        segment_future = executor.submit(process_segment, req.frame_base64)\n",
        "        caption_future = executor.submit(process_caption, req.frame_base64)\n",
        "\n",
        "        # Wait for both to complete\n",
        "        segment_result = segment_future.result()\n",
        "        caption_result = caption_future.result()\n",
        "\n",
        "        # Store in RDS only\n",
        "        storage_result = store_frame_data(\n",
        "            patient_id=req.patient_id,\n",
        "            session_id=req.session_id,\n",
        "            frame_base64=req.frame_base64,\n",
        "            segmented_frame=segment_result['segmented_frame'],\n",
        "            caption=caption_result\n",
        "        )\n",
        "\n",
        "        # Return results\n",
        "        return {\n",
        "            \"analysis_id\": storage_result[\"analysis_id\"],\n",
        "            \"patient_id\": req.patient_id,\n",
        "            \"session_id\": req.session_id,\n",
        "            \"segmented_frame\": segment_result['segmented_frame'],\n",
        "            \"caption\": caption_result,\n",
        "            \"original_image_url\": storage_result[\"original_url\"],\n",
        "            \"segmented_image_url\": storage_result[\"segmented_url\"]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Frame processing error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPwsr7QBIKrU"
      },
      "outputs": [],
      "source": [
        "# Add endpoint to retrieve analysis from RDS by analysis_id\n",
        "@app.get(\"/get_analysis/{analysis_id}\")\n",
        "async def get_analysis(analysis_id: int):\n",
        "    \"\"\"\n",
        "    Retrieve full analysis including caption from RDS\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            f\"{IMAGE_ANALYSIS_API}/{analysis_id}\",\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            raise HTTPException(\n",
        "                status_code=response.status_code,\n",
        "                detail=f\"Failed to retrieve analysis: {response.text}\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJksxl0XIMvb"
      },
      "outputs": [],
      "source": [
        "# Query endpoint to search by patient or session\n",
        "@app.get(\"/query_analyses\")\n",
        "async def query_analyses(\n",
        "    patient_id: str = None,\n",
        "    session_id: str = None,\n",
        "    limit: int = 10\n",
        "):\n",
        "    \"\"\"\n",
        "    Query analyses from RDS by patient_id or session_id\n",
        "    \"\"\"\n",
        "    try:\n",
        "        params = {}\n",
        "        if patient_id:\n",
        "            params['patient_id'] = patient_id\n",
        "        if session_id:\n",
        "            params['session_id'] = session_id\n",
        "        params['limit'] = limit\n",
        "\n",
        "        response = requests.get(\n",
        "            IMAGE_ANALYSIS_API,\n",
        "            params=params,\n",
        "            timeout=10\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            raise HTTPException(\n",
        "                status_code=response.status_code,\n",
        "                detail=f\"Failed to query analyses: {response.text}\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0vyHVMuD5QG",
        "outputId": "e5f7c829-c821-49af-f2c3-93b56d5273cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŒ Public URL: NgrokTunnel: \"https://3764327af39b.ngrok-free.app\" -> \"http://localhost:6111\"\n",
            "\n",
            "âœ… Server is ready!\n",
            "\n",
            "Use this URL in Unity:\n",
            "   NgrokTunnel: \"https://3764327af39b.ngrok-free.app\" -> \"http://localhost:6111\"/segment\n",
            "\n",
            "Test health check:\n",
            "   NgrokTunnel: \"https://3764327af39b.ngrok-free.app\" -> \"http://localhost:6111\"/health\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [2713]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:6111 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Uploaded to S3: original/1763926741_78abe2de-43ce-4c00-875e-00eb2db71ad5.png\n",
            "âœ… Uploaded to S3: segmented/1763926742_7b402641-1bfd-4af8-9069-276756663043.png\n",
            "âœ… Stored in DB with analysis_id: 12\n",
            "âœ… Stored in RDS with analysis_id: 12\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926747_3bcc8988-129c-4550-8d4d-9405f24350b0.png\n",
            "âœ… Uploaded to S3: segmented/1763926747_9ce9ba9a-abe9-4cca-af8b-25b87a1c27e7.png\n",
            "âœ… Stored in DB with analysis_id: 13\n",
            "âœ… Stored in RDS with analysis_id: 13\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926752_5134d6fc-9ac1-403f-8c7e-8b88160fa48e.png\n",
            "âœ… Uploaded to S3: segmented/1763926752_cbac2b1e-9dfd-498a-b813-908d31a0b731.png\n",
            "âœ… Stored in DB with analysis_id: 14\n",
            "âœ… Stored in RDS with analysis_id: 14\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926757_074312c1-2364-4dcf-a664-53748c429e30.png\n",
            "âœ… Uploaded to S3: segmented/1763926758_daf8b83f-37cd-4a30-8d7c-0fbafc5b42ce.png\n",
            "âœ… Stored in DB with analysis_id: 15\n",
            "âœ… Stored in RDS with analysis_id: 15\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926763_f6583f2e-8320-41a0-a2c1-3c3922a262f5.png\n",
            "âœ… Uploaded to S3: segmented/1763926763_99771dd2-2fae-4018-8a1b-404692b2918a.png\n",
            "âœ… Stored in DB with analysis_id: 16\n",
            "âœ… Stored in RDS with analysis_id: 16\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 422 Unprocessable Entity\n",
            "âœ… Uploaded to S3: original/1763926851_867895c2-f501-4af2-80ef-d9e4af34d6ab.png\n",
            "âœ… Uploaded to S3: segmented/1763926851_86939822-b6ad-4b61-8363-64bba8ac6f5e.png\n",
            "âœ… Stored in DB with analysis_id: 17\n",
            "âœ… Stored in RDS with analysis_id: 17\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926857_58c13dcc-dbe6-42b5-b0db-39b7654ba7ed.png\n",
            "âœ… Uploaded to S3: segmented/1763926857_1bc585ff-2a59-4a6f-ba6c-30fd67963e37.png\n",
            "âœ… Stored in DB with analysis_id: 18\n",
            "âœ… Stored in RDS with analysis_id: 18\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926861_a55d2a32-075c-46cd-b1ca-2c26f78511b2.png\n",
            "âœ… Uploaded to S3: segmented/1763926861_faa761b5-8848-4d44-9573-3c7ba14a6e31.png\n",
            "âœ… Stored in DB with analysis_id: 19\n",
            "âœ… Stored in RDS with analysis_id: 19\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926866_03d877c4-86a7-4547-bc56-0b49a097b947.png\n",
            "âœ… Uploaded to S3: segmented/1763926866_5009f6f9-600a-4f84-88de-40b46afa96e7.png\n",
            "âœ… Stored in DB with analysis_id: 20\n",
            "âœ… Stored in RDS with analysis_id: 20\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n",
            "âœ… Uploaded to S3: original/1763926870_115481da-0828-42ae-ad85-0033ca1f15ec.png\n",
            "âœ… Uploaded to S3: segmented/1763926871_9583254e-05e0-4c26-8e59-338ada87cf16.png\n",
            "âœ… Stored in DB with analysis_id: 21\n",
            "âœ… Stored in RDS with analysis_id: 21\n",
            "INFO:     174.114.222.197:0 - \"POST /process_frames HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    # Initialize S3 Manager\n",
        "    # add ur bucket name and AWS access creds\n",
        "    s3_manager = S3ImageStorageManager(\n",
        "        bucket_name='',\n",
        "        aws_access_key_id=\"\",\n",
        "        aws_secret_access_key=\"\"\n",
        "    )\n",
        "\n",
        "    # Initialize OpenAI client\n",
        "    # add your openai KEY!\n",
        "    initialize_openai(\n",
        "        api_key=\"sk-proj\"\n",
        "    )\n",
        "\n",
        "    # Ngrok setup\n",
        "    # add your ngrok auth token!\n",
        "    NGROK_AUTH_TOKEN = \"\"\n",
        "    server_thread = setup_and_run_server(app, NGROK_AUTH_TOKEN, port=6111)\n",
        "\n",
        "    # Optional: Keep the main thread alive\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nServer stopped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC6kfjPZD5QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbay_aqSD5QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qILDEB6KD5QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKFbUnUaD5QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7nn5kGhD5QH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj63OMO5EByB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
